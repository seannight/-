"""
æ•°æ®å¯è§†åŒ–æ¼”ç¤ºè„šæœ¬ - å±•ç¤ºç«èµ›æ•°æ®åˆ†æä¸å¯è§†åŒ–åŠŸèƒ½
ä½œè€…: Bæˆå‘˜
æ—¥æœŸ: 2023-04-08
æ›´æ–°: 2023-04-10 - ä¿®æ”¹ä¸ºç›´æ¥ä½¿ç”¨ç«èµ›ä¿¡æ¯æå–ç»“æœ.xlsxæ–‡ä»¶
æ›´æ–°: 2023-04-12 - æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒå’Œç¤ºä¾‹æ•°æ®ä½¿ç”¨åŠŸèƒ½
æ›´æ–°: 2023-04-22 - æ”¹è¿›ä¸­æ–‡å­—ä½“æ”¯æŒ
"""

import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import warnings
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
import argparse

# æ·»åŠ çˆ¶ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from app.data_processing.data_analyzer import DataAnalyzer

# å¿½ç•¥è­¦å‘Šä¿¡æ¯
warnings.filterwarnings("ignore")

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ•°æ®å¯è§†åŒ–æ¼”ç¤º"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ç«èµ›æ•°æ®å¯è§†åŒ–æ¼”ç¤º')
    parser.add_argument('--sample', action='store_true', help='ä½¿ç”¨ç¤ºä¾‹æ•°æ®è€Œéå®é™…æ•°æ®')
    args = parser.parse_args()
    
    # ç¡®å®šä½¿ç”¨çš„æ•°æ®æ–‡ä»¶
    data_file = "data/processed/ç«èµ›ä¿¡æ¯æå–ç»“æœ.xlsx"
    if args.sample:
        sample_file = "data/processed/ç«èµ›ä¿¡æ¯æå–ç»“æœ_ç¤ºä¾‹.xlsx"
        if os.path.exists(sample_file):
            data_file = sample_file
            print(f"ä½¿ç”¨ç¤ºä¾‹æ•°æ®: {sample_file}")
    elif os.path.exists("temp_config.txt"):
        with open("temp_config.txt", "r") as f:
            for line in f:
                if line.startswith("data_file="):
                    custom_file = line.strip().split("=")[1]
                    if os.path.exists(custom_file):
                        data_file = custom_file
                        print(f"ä½¿ç”¨é…ç½®æŒ‡å®šçš„æ•°æ®æ–‡ä»¶: {data_file}")
    
    # æ‰“å°æ¬¢è¿ä¿¡æ¯
    print_welcome()
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    if not check_data_paths(data_file):
        print("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¡®è®¤æ•°æ®ç›®å½•å­˜åœ¨")
        return
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = DataAnalyzer(metadata_file=data_file)
    
    # åŠ è½½æ•°æ®
    print("â³ æ­£åœ¨åŠ è½½æ•°æ®...")
    if not analyzer.load_data():
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return
    
    print("âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    
    # é€‰æ‹©æ¼”ç¤ºæ¨¡å—
    while True:
        choice = show_menu()
        
        if choice == "1":
            # å…ƒæ•°æ®åˆ†æ
            print("\nğŸ” å…ƒæ•°æ®åˆ†æ...\n")
            metadata_analysis = analyzer.analyze_metadata()
            print_metadata_analysis(metadata_analysis)
            
        elif choice == "2":
            # è¡¨æ ¼åˆ†æ
            print("\nğŸ” è¡¨æ ¼æ•°æ®åˆ†æ...\n")
            table_analysis = analyzer.analyze_tables()
            print_table_analysis(table_analysis)
            
        elif choice == "3":
            # å…ƒæ•°æ®å¯è§†åŒ–
            print("\nğŸ“Š ç”Ÿæˆå…ƒæ•°æ®å¯è§†åŒ–å›¾è¡¨...\n")
            analyzer.generate_metadata_visualizations()
            print_visualization_paths("å…ƒæ•°æ®")
            
        elif choice == "4":
            # è¡¨æ ¼å¯è§†åŒ–
            print("\nğŸ“Š ç”Ÿæˆè¡¨æ ¼æ•°æ®å¯è§†åŒ–å›¾è¡¨...\n")
            analyzer.generate_tables_visualizations()
            print_visualization_paths("è¡¨æ ¼æ•°æ®")
            
        elif choice == "5":
            # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            print("\nğŸ“ ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š...\n")
            report = analyzer.generate_comprehensive_report()
            print_report_summary(report)
            
        elif choice == "6":
            # è¿è¡Œå…¨éƒ¨åˆ†æ
            print("\nğŸš€ è¿è¡Œå®Œæ•´æ•°æ®åˆ†ææµç¨‹...\n")
            analyzer.run_full_analysis()
            print("\nâœ… å®Œæ•´åˆ†ææµç¨‹å·²å®Œæˆ")
            print_all_output_paths()
            
        elif choice == "0":
            print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ•°æ®å¯è§†åŒ–æ¼”ç¤ºç³»ç»Ÿï¼Œå†è§ï¼")
            break
            
        else:
            print("\nâŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

def print_welcome():
    """æ‰“å°æ¬¢è¿ä¿¡æ¯"""
    print("\n" + "="*60)
    print("ğŸ† ç«èµ›æ•°æ®åˆ†æä¸å¯è§†åŒ–æ¼”ç¤ºç³»ç»Ÿ ğŸ†".center(58))
    print("="*60)
    print("æœ¬ç³»ç»Ÿå±•ç¤ºä»ç«èµ›PDFæ–‡ä»¶ä¸­æå–çš„æ•°æ®åˆ†æä¸å¯è§†åŒ–åŠŸèƒ½")
    print("å¯ä»¥ç”Ÿæˆç»Ÿè®¡åˆ†æã€å›¾è¡¨å¯è§†åŒ–å’Œç»¼åˆæŠ¥å‘Š")
    print("-"*60)

def check_data_paths(data_file="data/processed/ç«èµ›ä¿¡æ¯æå–ç»“æœ.xlsx"):
    """
    æ£€æŸ¥å¿…è¦çš„æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨
    
    å‚æ•°:
        data_file: è¦æ£€æŸ¥çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿æ‰€æœ‰å¿…è¦çš„ç›®å½•éƒ½å­˜åœ¨
    required_paths = [
        "data/processed",
        "data/analysis",
        "data/analysis/plots",
        "data/analysis/reports",
        "logs"
    ]
    
    for path in required_paths:
        if not os.path.exists(path):
            print(f"åˆ›å»ºç›®å½•: {path}")
            os.makedirs(path, exist_ok=True)
    
    # æ£€æŸ¥å…ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(data_file):
        print(f"âš ï¸ è­¦å‘Š: å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return False
    
    print(f"âœ… æ‰¾åˆ°å…ƒæ•°æ®æ–‡ä»¶: {data_file}")
    return True

def show_menu():
    """æ˜¾ç¤ºèœå•å¹¶è·å–ç”¨æˆ·é€‰æ‹©"""
    print("\n" + "-"*60)
    print("ğŸ“‹ åŠŸèƒ½èœå•:".center(58))
    print("-"*60)
    print("1. å…ƒæ•°æ®åˆ†æ - åˆ†æç«èµ›åŸºæœ¬ä¿¡æ¯")
    print("2. è¡¨æ ¼æ•°æ®åˆ†æ - åˆ†ææå–çš„è¡¨æ ¼ç»“æ„")
    print("3. å…ƒæ•°æ®å¯è§†åŒ– - ç”Ÿæˆå…ƒæ•°æ®å›¾è¡¨")
    print("4. è¡¨æ ¼æ•°æ®å¯è§†åŒ– - ç”Ÿæˆè¡¨æ ¼åˆ†æå›¾è¡¨")
    print("5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š - åˆ›å»ºå®Œæ•´åˆ†ææŠ¥å‘Š")
    print("6. è¿è¡Œå…¨éƒ¨åˆ†æ - æ‰§è¡Œæ‰€æœ‰åˆ†ææ­¥éª¤")
    print("0. é€€å‡ºç³»ç»Ÿ")
    print("-"*60)
    
    return input("è¯·è¾“å…¥é€‰é¡¹ [0-6]: ")

def print_metadata_analysis(analysis):
    """æ‰“å°å…ƒæ•°æ®åˆ†æç»“æœ"""
    if not analysis:
        print("âŒ å…ƒæ•°æ®åˆ†æç»“æœä¸ºç©º")
        return
    
    print(f"ğŸ“Š åˆ†æäº† {analysis['total_competitions']} ä¸ªç«èµ›æ•°æ®")
    
    if 'organization_counts' in analysis:
        print("\nğŸ“‹ ç»„ç»‡å•ä½ç»Ÿè®¡ (Top 5):")
        org_counts = dict(sorted(analysis['organization_counts'].items(), 
                                key=lambda x: x[1], reverse=True)[:5])
        for org, count in org_counts.items():
            print(f"  - {org}: {count} ä¸ªç«èµ›")
    
    if 'year_counts' in analysis:
        print("\nğŸ“… ç«èµ›æŒ‰å¹´ä»½åˆ†å¸ƒ:")
        year_counts = dict(sorted(analysis['year_counts'].items()))
        for year, count in year_counts.items():
            print(f"  - {year}å¹´: {count} ä¸ªç«èµ›")
    
    if 'level_counts' in analysis:
        print("\nğŸ… ç«èµ›çº§åˆ«åˆ†å¸ƒ:")
        for level, count in analysis['level_counts'].items():
            print(f"  - {level}: {count} ä¸ªç«èµ›")
    
    print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜è‡³: data/analysis/reports/metadata_analysis.json")

def print_table_analysis(analysis):
    """æ‰“å°è¡¨æ ¼åˆ†æç»“æœ"""
    if not analysis:
        print("âŒ è¡¨æ ¼åˆ†æç»“æœä¸ºç©º")
        return
    
    print(f"ğŸ“Š æ€»è¡¨æ ¼æ•°: {analysis['total_tables']}")
    print(f"ğŸ“ å¹³å‡è¡Œæ•°: {analysis['avg_rows_per_table']:.2f}")
    print(f"ğŸ“ å¹³å‡åˆ—æ•°: {analysis['avg_cols_per_table']:.2f}")
    print(f"âš ï¸ ç©ºè¡¨æ ¼æ•°: {analysis['empty_tables']}")
    print(f"ğŸ“ˆ å¤§å‹è¡¨æ ¼(>20è¡Œ): {analysis['large_tables']}")
    
    print("\nğŸ“‹ è¡¨æ ¼æ•°é‡æœ€å¤šçš„æ–‡ä»¶ (Top 5):")
    top_files = dict(sorted(analysis['tables_per_file'].items(), 
                          key=lambda x: x[1], reverse=True)[:5])
    for file, count in top_files.items():
        print(f"  - {file}: {count} ä¸ªè¡¨æ ¼")
    
    print(f"\nâœ… åˆ†æç»“æœå·²ä¿å­˜è‡³: data/analysis/reports/tables_analysis.json")

def print_visualization_paths(data_type):
    """æ‰“å°å¯è§†åŒ–å›¾è¡¨è·¯å¾„"""
    plots_dir = "data/analysis/plots"
    
    # è·å–ç›¸å…³å›¾è¡¨æ–‡ä»¶
    if data_type == "å…ƒæ•°æ®":
        relevant_files = [
            "competition_levels_pie.png",
            "top_organizations_bar.png",
            "competitions_by_year.png",
            "correlation_heatmap.png"
        ]
    else:  # è¡¨æ ¼æ•°æ®
        relevant_files = [
            "tables_per_file.png",
            "table_dimensions_scatter.png",
            "table_rows_histogram.png"
        ]
    
    print(f"ğŸ“Š {data_type}å¯è§†åŒ–å›¾è¡¨å·²ç”Ÿæˆ:")
    for file in relevant_files:
        path = os.path.join(plots_dir, file)
        if os.path.exists(path):
            print(f"  - {path}")
    
    # æ£€æŸ¥äº¤äº’å¼å›¾è¡¨
    html_files = [f for f in os.listdir(plots_dir) if f.endswith(".html")]
    if html_files:
        print("\nğŸŒ äº¤äº’å¼å›¾è¡¨ (HTML):")
        for file in html_files:
            if (data_type == "å…ƒæ•°æ®" and any(x in file for x in ["competition", "organization", "year"])) or \
               (data_type == "è¡¨æ ¼æ•°æ®" and any(x in file for x in ["table", "dimension"])):
                print(f"  - {os.path.join(plots_dir, file)}")

def print_report_summary(report):
    """æ‰“å°ç»¼åˆæŠ¥å‘Šæ‘˜è¦"""
    if not report:
        print("âŒ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        return
    
    print("ğŸ“ ç»¼åˆæŠ¥å‘Šæ‘˜è¦:")
    print(f"  - ç”Ÿæˆæ—¶é—´: {report['ç”Ÿæˆæ—¶é—´']}")
    print(f"  - ç«èµ›æ€»æ•°: {report['å…ƒæ•°æ®ç»Ÿè®¡']['ç«èµ›æ€»æ•°']}")
    
    if 'æ•°æ®è´¨é‡è¯„ä¼°' in report:
        print(f"  - å…ƒæ•°æ®å®Œæ•´åº¦: {report['æ•°æ®è´¨é‡è¯„ä¼°']['å…ƒæ•°æ®å®Œæ•´åº¦']}")
    
    if 'å»ºè®®' in report and report['å»ºè®®']:
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®:")
        for suggestion in report['å»ºè®®']:
            print(f"  - {suggestion}")
    
    print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜è‡³:")
    print(f"  - data/analysis/reports/comprehensive_report.json")
    print(f"  - data/analysis/reports/comprehensive_report.html")

def print_all_output_paths():
    """æ‰“å°æ‰€æœ‰è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    print("\nğŸ“‚ åˆ†æç»“æœæ–‡ä»¶:")
    
    # æŠ¥å‘Šæ–‡ä»¶
    reports_dir = "data/analysis/reports"
    if os.path.exists(reports_dir):
        print("\nğŸ“ æŠ¥å‘Šæ–‡ä»¶:")
        for file in os.listdir(reports_dir):
            print(f"  - {os.path.join(reports_dir, file)}")
    
    # å›¾è¡¨æ–‡ä»¶
    plots_dir = "data/analysis/plots"
    if os.path.exists(plots_dir):
        print("\nğŸ“Š å¯è§†åŒ–å›¾è¡¨:")
        png_files = [f for f in os.listdir(plots_dir) if f.endswith(".png")]
        for file in png_files:
            print(f"  - {os.path.join(plots_dir, file)}")
        
        print("\nğŸŒ äº¤äº’å¼å›¾è¡¨ (HTML):")
        html_files = [f for f in os.listdir(plots_dir) if f.endswith(".html")]
        for file in html_files:
            print(f"  - {os.path.join(plots_dir, file)}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc() 